'use client'

import { useState, useRef, useEffect } from 'react'
import type { Mensaje, EstadoConversacion } from '@/types'

interface VistaMovilVozProps {
  onCitaCreada?: () => void
  onEnviarWhatsApp?: (mensaje: string) => void
}

export default function VistaMovilVoz({ onCitaCreada, onEnviarWhatsApp }: VistaMovilVozProps) {
  const [mensajes, setMensajes] = useState<Mensaje[]>([])
  const [llamadaActiva, setLlamadaActiva] = useState(false)
  const [escuchando, setEscuchando] = useState(false)
  const [hablando, setHablando] = useState(false)
  const [estado, setEstado] = useState<EstadoConversacion>({
    paso: 'inicio',
    datosTemporales: {},
  })

  const recognitionRef = useRef<any>(null)
  const synthesisRef = useRef<SpeechSynthesis | null>(null)
  const mensajesRef = useRef<HTMLDivElement>(null)
  const hablandoRef = useRef<boolean>(false)
  const llamadaActivaRef = useRef<boolean>(false)
  const mejorVozRef = useRef<SpeechSynthesisVoice | null>(null)

  useEffect(() => {
    if (typeof window !== 'undefined') {
      synthesisRef.current = window.speechSynthesis

      // Buscar la mejor voz en espa√±ol disponible
      const cargarVoces = () => {
        const voces = window.speechSynthesis.getVoices()
        console.log('Voces disponibles:', voces.map(v => ({ name: v.name, lang: v.lang })))

        // Priorizar voces premium/enhanced de Espa√±a o Latinoam√©rica
        const vocesEspanol = voces.filter(v =>
          v.lang.startsWith('es-') || v.lang === 'es'
        )

        // Buscar voces premium (Google, Microsoft, Apple) en orden de prioridad
        const vozPreferida =
          vocesEspanol.find(v => v.name.includes('Premium') && v.name.includes('Female')) ||
          vocesEspanol.find(v => v.name.includes('Google') && v.name.includes('es-ES')) ||
          vocesEspanol.find(v => v.name.includes('Microsoft') && v.name.includes('Female')) ||
          vocesEspanol.find(v => v.name.includes('M√≥nica')) || // Microsoft ES voice
          vocesEspanol.find(v => v.name.includes('Paulina')) || // macOS voice
          vocesEspanol.find(v => v.name.includes('Female')) ||
          vocesEspanol.find(v => v.lang === 'es-ES') ||
          vocesEspanol[0]

        if (vozPreferida) {
          mejorVozRef.current = vozPreferida
          console.log('Voz seleccionada:', vozPreferida.name, vozPreferida.lang)
        }
      }

      // Las voces pueden tardar en cargar, as√≠ que esperamos
      if (window.speechSynthesis.getVoices().length > 0) {
        cargarVoces()
      } else {
        window.speechSynthesis.onvoiceschanged = cargarVoces
      }
    }
  }, [])

  useEffect(() => {
    if (mensajesRef.current) {
      mensajesRef.current.scrollTop = mensajesRef.current.scrollHeight
    }
  }, [mensajes])

  const hablar = (texto: string) => {
    return new Promise<void>((resolve) => {
      if (!synthesisRef.current || !texto || texto.trim() === '') {
        console.warn('No se puede hablar - synthesisRef o texto vac√≠o')
        resolve()
        return
      }

      // Cancelar cualquier voz anterior
      synthesisRef.current.cancel()

      const utterance = new SpeechSynthesisUtterance(texto)

      // Usar la mejor voz disponible o fallback a voz por defecto
      try {
        if (mejorVozRef.current) {
          utterance.voice = mejorVozRef.current
          utterance.lang = mejorVozRef.current.lang
        } else {
          utterance.lang = 'es-ES'
        }
      } catch (e) {
        console.warn('Error al setear voz, usando default:', e)
        utterance.lang = 'es-ES'
      }

      // Ajustes para que suene m√°s natural
      utterance.rate = 0.95
      utterance.pitch = 1.05
      utterance.volume = 1.0

      setHablando(true)
      hablandoRef.current = true

      let haResolved = false

      utterance.onend = () => {
        if (!haResolved) {
          haResolved = true
          setHablando(false)
          hablandoRef.current = false
          resolve()
        }
      }

      utterance.onerror = (error) => {
        console.error('Error al hablar:', error)
        if (!haResolved) {
          haResolved = true
          setHablando(false)
          hablandoRef.current = false
          // Intentar de nuevo sin voz espec√≠fica
          if (mejorVozRef.current) {
            console.log('Reintentando sin voz espec√≠fica...')
            mejorVozRef.current = null
            // No hacer resolve aqu√≠, dejar que el timeout lo maneje
          }
          resolve()
        }
      }

      // Timeout de seguridad
      setTimeout(() => {
        if (!haResolved) {
          console.warn('Timeout al hablar, forzando resolve')
          haResolved = true
          setHablando(false)
          hablandoRef.current = false
          resolve()
        }
      }, 30000) // 30 segundos m√°ximo

      try {
        synthesisRef.current.speak(utterance)
      } catch (e) {
        console.error('Error al ejecutar speak:', e)
        if (!haResolved) {
          haResolved = true
          setHablando(false)
          hablandoRef.current = false
          resolve()
        }
      }
    })
  }

  const iniciarReconocimiento = () => {
    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      alert('Tu navegador no soporta reconocimiento de voz. Usa Chrome o Edge.')
      return
    }

    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition
    recognitionRef.current = new SpeechRecognition()
    recognitionRef.current.lang = 'es-ES'
    recognitionRef.current.continuous = false
    recognitionRef.current.interimResults = false

    recognitionRef.current.onstart = () => {
      setEscuchando(true)
    }

    recognitionRef.current.onresult = async (event: any) => {
      const transcript = event.results[0][0].transcript
      setEscuchando(false)

      // Agregar mensaje del usuario
      const mensajeUsuario: Mensaje = {
        id: Date.now().toString(),
        role: 'user',
        content: transcript,
        timestamp: new Date(),
      }
      setMensajes((prev) => [...prev, mensajeUsuario])

      // Enviar a OpenAI
      await procesarRespuesta(transcript)
    }

    recognitionRef.current.onerror = (event: any) => {
      console.error('Error de reconocimiento:', event.error)
      setEscuchando(false)

      // No reintentar si el error es "aborted" (el usuario lo cancel√≥) o "no-speech" (no detect√≥ nada)
      if (event.error === 'aborted' || event.error === 'not-allowed') {
        console.log('Reconocimiento cancelado por el usuario o no permitido')
        return
      }

      if (llamadaActivaRef.current && !hablandoRef.current) {
        // Reintentar solo si no estamos hablando
        console.log('Reintentando reconocimiento tras error:', event.error)
        setTimeout(() => {
          if (recognitionRef.current && llamadaActivaRef.current && !hablandoRef.current) {
            try {
              recognitionRef.current.start()
            } catch (e) {
              console.log('No se pudo reiniciar:', e)
            }
          }
        }, 1000)
      }
    }

    recognitionRef.current.onend = () => {
      setEscuchando(false)
      // Si la llamada sigue activa y no estamos hablando, reiniciar autom√°ticamente
      if (llamadaActivaRef.current && !hablandoRef.current) {
        setTimeout(() => {
          if (recognitionRef.current && llamadaActivaRef.current && !hablandoRef.current) {
            try {
              recognitionRef.current.start()
            } catch (e) {
              console.log('Recognition ya est√° iniciado o hubo un error:', e)
            }
          }
        }, 300)
      }
    }

    recognitionRef.current.start()
  }

  const procesarRespuesta = async (textoUsuario: string) => {
    try {
      console.log('Enviando a OpenAI:', textoUsuario)

      const response = await fetch('/api/chat', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          mensajes: [...mensajes, {
            id: Date.now().toString(),
            role: 'user',
            content: textoUsuario,
            timestamp: new Date(),
          }],
          estado,
        }),
      })

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`)
      }

      const data = await response.json()
      console.log('Respuesta de OpenAI:', data)

      if (!data.respuesta) {
        throw new Error('No se recibi√≥ respuesta del agente')
      }

      const mensajeAgent: Mensaje = {
        id: (Date.now() + 1).toString(),
        role: 'agent',
        content: data.respuesta,
        timestamp: new Date(),
      }

      setMensajes((prev) => [...prev, mensajeAgent])
      const nuevoEstado = data.nuevoEstado || estado
      setEstado(nuevoEstado)

      // El agente habla la respuesta
      console.log('Agente va a hablar:', data.respuesta)
      await hablar(data.respuesta)
      console.log('Agente termin√≥ de hablar')

      // Si tenemos todos los datos, preparar para confirmar
      if (
        nuevoEstado.accion === 'crear' &&
        nuevoEstado.datosTemporales.nombre &&
        nuevoEstado.datosTemporales.telefono &&
        nuevoEstado.datosTemporales.motivo &&
        !nuevoEstado.datosTemporales.fecha
      ) {
        const fechaSugerida = new Date()
        fechaSugerida.setDate(fechaSugerida.getDate() + 3)
        nuevoEstado.datosTemporales.fecha = fechaSugerida.toISOString().split('T')[0]
        nuevoEstado.datosTemporales.hora = '10:00'
        setEstado(nuevoEstado)

        // Preguntar si quiere confirmar
        const preguntaConfirmacion = '¬øDeseas confirmar esta cita? Di "s√≠" para confirmar o "no" para cancelar.'
        await hablar(preguntaConfirmacion)

        const mensajeConfirmacion: Mensaje = {
          id: (Date.now() + 2).toString(),
          role: 'agent',
          content: preguntaConfirmacion,
          timestamp: new Date(),
        }
        setMensajes((prev) => [...prev, mensajeConfirmacion])
      }

      // Continuar escuchando si la llamada est√° activa
      console.log('Preparando para volver a escuchar...')
      console.log('Estado actual - llamadaActiva:', llamadaActiva, 'recognitionRef:', !!recognitionRef.current)
      if (llamadaActivaRef.current && recognitionRef.current) {
        setTimeout(() => {
          console.log('Dentro del setTimeout - llamadaActivaRef.current:', llamadaActivaRef.current, 'hablandoRef.current:', hablandoRef.current)
          if (recognitionRef.current && llamadaActivaRef.current) {
            console.log('Reiniciando reconocimiento de voz')
            try {
              recognitionRef.current.start()
            } catch (e: any) {
              console.log('Error al reiniciar reconocimiento:', e.message)
              // Si el error es que ya est√° iniciado, no hacer nada
              if (!e.message.includes('already')) {
                console.error('Error inesperado:', e)
              }
            }
          } else {
            console.log('No se puede reiniciar - condiciones no cumplidas')
          }
        }, 1000)
      } else {
        console.log('No se program√≥ el reinicio - condiciones iniciales no cumplidas')
      }

    } catch (error) {
      console.error('Error:', error)
      const mensajeError = 'Lo siento, hubo un error. ¬øPodr√≠as repetir?'
      await hablar(mensajeError)

      if (llamadaActivaRef.current && recognitionRef.current) {
        setTimeout(() => {
          if (recognitionRef.current && llamadaActivaRef.current) {
            try {
              recognitionRef.current.start()
            } catch (e) {
              console.log('Error al reiniciar tras error:', e)
            }
          }
        }, 1000)
      }
    }
  }

  const iniciarLlamada = async () => {
    setLlamadaActiva(true)
    llamadaActivaRef.current = true

    const mensajeBienvenida: Mensaje = {
      id: Date.now().toString(),
      role: 'agent',
      content: 'Hola, bienvenido a la Cl√≠nica Dental. ¬øEn qu√© puedo ayudarte?',
      timestamp: new Date(),
    }
    setMensajes([mensajeBienvenida])
    setEstado({
      paso: 'inicio',
      datosTemporales: {},
    })

    // El agente habla primero
    await hablar(mensajeBienvenida.content)

    // Luego empieza a escuchar
    iniciarReconocimiento()
  }

  const finalizarLlamada = () => {
    setLlamadaActiva(false)
    llamadaActivaRef.current = false
    setEscuchando(false)
    setHablando(false)
    hablandoRef.current = false

    if (recognitionRef.current) {
      recognitionRef.current.stop()
      recognitionRef.current = null
    }

    if (synthesisRef.current) {
      synthesisRef.current.cancel()
    }

    setMensajes([])
    setEstado({ paso: 'inicio', datosTemporales: {} })
  }

  const formatearFecha = (fecha: string) => {
    const date = new Date(fecha + 'T00:00:00')
    return date.toLocaleDateString('es-ES', {
      weekday: 'long',
      day: 'numeric',
      month: 'long',
    })
  }

  return (
    <div className="flex gap-8 items-start max-w-6xl mx-auto">
      {/* M√≥vil */}
      <div className="flex-shrink-0">
        <div className="w-[340px] h-[680px] bg-gray-900 rounded-[50px] p-3 shadow-2xl relative">
          {/* Notch */}
          <div className="absolute top-0 left-1/2 -translate-x-1/2 w-40 h-7 bg-gray-900 rounded-b-3xl z-10"></div>

          {/* Pantalla */}
          <div className="w-full h-full bg-white rounded-[40px] overflow-hidden flex flex-col">
            {!llamadaActiva ? (
              <div className="flex-1 flex flex-col items-center justify-center p-8">
                <div className="w-24 h-24 bg-[#01336c] rounded-full flex items-center justify-center mb-6 animate-pulse">
                  <span className="text-5xl">üìû</span>
                </div>
                <h3 className="text-xl font-bold text-gray-900 mb-2">
                  Llamada de Voz
                </h3>
                <p className="text-sm text-gray-600 text-center mb-6">
                  Habla naturalmente con el asistente virtual
                </p>
                <button
                  onClick={iniciarLlamada}
                  className="bg-[#01336c] hover:bg-[#03366d] text-white px-8 py-3 rounded-full font-semibold transition-colors shadow-lg"
                >
                  üìû Iniciar Llamada
                </button>
              </div>
            ) : (
              <>
                {/* Header */}
                <div className="bg-[#01336c] text-white p-4 flex items-center justify-between">
                  <div className="flex items-center gap-3">
                    <div className="w-10 h-10 bg-white/20 rounded-full flex items-center justify-center">
                      {hablando ? (
                        <span className="text-xl animate-pulse">üîä</span>
                      ) : escuchando ? (
                        <span className="text-xl animate-pulse">üé§</span>
                      ) : (
                        <span className="text-xl">ü§ñ</span>
                      )}
                    </div>
                    <div>
                      <p className="font-semibold">Asistente Virtual</p>
                      <p className="text-xs opacity-80">
                        {hablando ? 'Hablando...' : escuchando ? 'Escuchando...' : 'En llamada'}
                      </p>
                    </div>
                  </div>
                  <button
                    onClick={finalizarLlamada}
                    className="w-10 h-10 bg-red-500 rounded-full flex items-center justify-center hover:bg-red-600 transition-colors"
                  >
                    <span className="text-xl">‚úï</span>
                  </button>
                </div>

                {/* √Årea de visualizaci√≥n de conversaci√≥n */}
                <div ref={mensajesRef} className="flex-1 overflow-y-auto p-4 space-y-3 bg-gray-50">
                  {mensajes.map((msg) => (
                    <div
                      key={msg.id}
                      className={`flex ${msg.role === 'user' ? 'justify-end' : 'justify-start'}`}
                    >
                      <div
                        className={`max-w-[80%] px-3 py-2 rounded-2xl text-sm ${
                          msg.role === 'user'
                            ? 'bg-[#01336c] text-white'
                            : 'bg-white text-gray-800 border border-gray-200'
                        }`}
                      >
                        <p>{msg.content}</p>
                      </div>
                    </div>
                  ))}
                </div>

                {/* Indicador de estado */}
                <div className="p-4 bg-white border-t border-gray-200">
                  <div className="flex items-center justify-center gap-2">
                    {hablando ? (
                      <>
                        <div className="w-2 h-2 bg-green-500 rounded-full animate-pulse"></div>
                        <span className="text-sm text-gray-600">El asistente est√° hablando...</span>
                      </>
                    ) : escuchando ? (
                      <>
                        <div className="w-2 h-2 bg-red-500 rounded-full animate-pulse"></div>
                        <span className="text-sm text-gray-600">Escuchando tu respuesta...</span>
                      </>
                    ) : (
                      <>
                        <div className="w-2 h-2 bg-blue-500 rounded-full"></div>
                        <span className="text-sm text-gray-600">Llamada activa</span>
                      </>
                    )}
                  </div>
                </div>
              </>
            )}
          </div>
        </div>
      </div>

      {/* Transcripci√≥n */}
      <div className="flex-1">
        <div className="bg-white rounded-lg border border-gray-200 p-6 h-[680px] flex flex-col">
          <h3 className="text-lg font-semibold text-gray-900 mb-4 flex items-center gap-2">
            <span>üìù</span>
            Transcripci√≥n en Tiempo Real
          </h3>
          <div className="flex-1 overflow-y-auto space-y-3">
            {mensajes.length === 0 ? (
              <p className="text-gray-500 text-sm text-center mt-12">
                La conversaci√≥n aparecer√° aqu√≠...
              </p>
            ) : (
              mensajes.map((msg) => (
                <div key={msg.id} className="space-y-1">
                  <p className="text-xs font-semibold text-gray-600">
                    {msg.role === 'agent' ? 'ü§ñ Asistente' : 'üë§ Usuario'}
                  </p>
                  <p className="text-sm text-gray-800 pl-5">{msg.content}</p>
                  <p className="text-xs text-gray-400 pl-5">
                    {msg.timestamp.toLocaleTimeString('es-ES', {
                      hour: '2-digit',
                      minute: '2-digit',
                    })}
                  </p>
                </div>
              ))
            )}
          </div>
        </div>
      </div>
    </div>
  )
}
